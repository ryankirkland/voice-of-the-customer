{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ryankirkland/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords,wordnet\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/total_reviews.csv')\n",
    "cleaned = pd.read_csv('../data/cleaned_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B08267BBJT', 'B08268F6XN', 'B08267X3LH', 'B079JFK22D',\n",
       "       'B07QW531W2', 'B07TJTQDYG', 'B085HB8QVX', 'B07R2KK5P7',\n",
       "       'B07Y475MD3', 'B07F27PK2M', 'B085FZFVQV', 'B072R2SWXX',\n",
       "       'B0828KRQZ3', 'B0821ZNWKW', 'B07QV15B3W', 'B07MWYYDTM',\n",
       "       'B07RSJMS76', 'B07D1LMMDD', 'B0855TM65T', 'B07NTXYFBV',\n",
       "       'B086L3Q8YX', 'B085FT4YR1', 'B085XT3GTW', 'B07P9XZPYG',\n",
       "       'B0824WB5ST', 'B07HQ7QV7W', 'B083ZMYF55', 'B07FQD7PZ5',\n",
       "       'B07TWDR7VJ', 'B085DV7VZK', 'B086GTFGPP', 'B07Q6PZ2F4',\n",
       "       'B082W54KQK'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['asin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(pos_tag):\n",
    "\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ \n",
    "\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB \n",
    "\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    \n",
    "    else:\n",
    "        return wordnet.NOUN # default, return wordnet tag \"NOUN\"\n",
    "\n",
    "#Create a function to lemmatize tokens in the reviews\n",
    "def lemmatized_tokens(text):\n",
    "        text = text.lower()\n",
    "        pattern = r'\\b[a-zA-Z]{3,}\\b'                 \n",
    "        tokens = nltk.regexp_tokenize(text, pattern) # tokenize the text\n",
    "        tagged_tokens = nltk.pos_tag(tokens)  # a list of tuples (word, pos_tag)\n",
    "          \n",
    "        stop_words = stopwords.words('english')\n",
    "        new_stopwords = []  #customize extra stop_words\n",
    "        stop_words.extend(new_stopwords)\n",
    "        stop_words = set(stop_words)\n",
    "        \n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        # get lemmatized tokens                             #call function \"get_wordnet_pos\"\n",
    "        lemmatized_words=[wordnet_lemmatizer.lemmatize(word, get_wordnet_pos(tag)) \n",
    "                  # tagged_tokens is a list of tuples (word, tag)\n",
    "                  for (word, tag) in tagged_tokens \\\n",
    "                  # remove stop words\n",
    "                  if word not in stop_words and \\\n",
    "                  # remove punctuations\n",
    "                  word not in string.punctuation]\n",
    "\n",
    "        return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = cleaned.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>product</th>\n",
       "      <th>date</th>\n",
       "      <th>verified</th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>month_year</th>\n",
       "      <th>title_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B08267BBJT</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>Verified Purchase</td>\n",
       "      <td>Didn't work, then worked, now don't work again</td>\n",
       "      <td>All I got in terms of use out of these batter...</td>\n",
       "      <td>Jasmine Carroll</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-08</td>\n",
       "      <td>Didn't work, then worked, now don't work again...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08267BBJT</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>Verified Purchase</td>\n",
       "      <td>These absolutely suck</td>\n",
       "      <td>I bought these for a wall mounted magnifying ...</td>\n",
       "      <td>Ashlee M.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>These absolutely suck I bought these for a wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B08268F6XN</td>\n",
       "      <td>AA</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>Verified Purchase</td>\n",
       "      <td>longer lasting battery for remote controller!!</td>\n",
       "      <td>i like the constant voltage and hopefully it ...</td>\n",
       "      <td>ARCHANGEL TROY</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>longer lasting battery for remote controller!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08267BBJT</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2020-07-18</td>\n",
       "      <td>Verified Purchase</td>\n",
       "      <td>Minimal plastic in packaging.</td>\n",
       "      <td>Just received these today, but Iâ€™m reviewing ...</td>\n",
       "      <td>ira</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>Minimal plastic in packaging. Just received th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B08267BBJT</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>Verified Purchase</td>\n",
       "      <td>Not long enough battery life for a night hike</td>\n",
       "      <td>Shuts off suddenly in headlamp</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>Not long enough battery life for a night hike ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin product        date           verified  \\\n",
       "0  B08267BBJT     AAA  2020-08-11  Verified Purchase   \n",
       "1  B08267BBJT     AAA  2020-07-30  Verified Purchase   \n",
       "2  B08268F6XN      AA  2020-07-19  Verified Purchase   \n",
       "3  B08267BBJT     AAA  2020-07-18  Verified Purchase   \n",
       "4  B08267BBJT     AAA  2020-07-17  Verified Purchase   \n",
       "\n",
       "                                            title  \\\n",
       "0  Didn't work, then worked, now don't work again   \n",
       "1                           These absolutely suck   \n",
       "2  longer lasting battery for remote controller!!   \n",
       "3                   Minimal plastic in packaging.   \n",
       "4   Not long enough battery life for a night hike   \n",
       "\n",
       "                                                desc    reviewer_name  rating  \\\n",
       "0   All I got in terms of use out of these batter...  Jasmine Carroll     1.0   \n",
       "1   I bought these for a wall mounted magnifying ...        Ashlee M.     1.0   \n",
       "2   i like the constant voltage and hopefully it ...   ARCHANGEL TROY     5.0   \n",
       "3   Just received these today, but Iâ€™m reviewing ...              ira     5.0   \n",
       "4                     Shuts off suddenly in headlamp                T     3.0   \n",
       "\n",
       "   month  year month_year                                         title_desc  \n",
       "0      8  2020    2020-08  Didn't work, then worked, now don't work again...  \n",
       "1      7  2020    2020-07  These absolutely suck I bought these for a wal...  \n",
       "2      7  2020    2020-07  longer lasting battery for remote controller!!...  \n",
       "3      7  2020    2020-07  Minimal plastic in packaging. Just received th...  \n",
       "4      7  2020    2020-07  Not long enough battery life for a night hike ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_txt = cleaned.loc[0, 'title_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed_test = lemmatized_tokens(test_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['work',\n",
       " 'work',\n",
       " 'work',\n",
       " 'get',\n",
       " 'term',\n",
       " 'use',\n",
       " 'battery',\n",
       " 'three',\n",
       " 'day',\n",
       " 'use',\n",
       " 'two',\n",
       " 'additional',\n",
       " 'success',\n",
       " 'buy',\n",
       " 'bleed',\n",
       " 'aaa',\n",
       " 'battery',\n",
       " 'hop',\n",
       " 'compact',\n",
       " 'design',\n",
       " 'would',\n",
       " 'better',\n",
       " 'something',\n",
       " 'bulky',\n",
       " 'right',\n",
       " 'box',\n",
       " 'charge',\n",
       " 'light',\n",
       " 'green',\n",
       " 'indicate',\n",
       " 'fully',\n",
       " 'charge',\n",
       " 'try',\n",
       " 'use',\n",
       " 'couple',\n",
       " 'device',\n",
       " 'luck',\n",
       " 'go',\n",
       " 'return',\n",
       " 'friend',\n",
       " 'suggest',\n",
       " 'switch',\n",
       " 'charge',\n",
       " 'extension',\n",
       " 'cord',\n",
       " 'directly',\n",
       " 'wall',\n",
       " 'socket',\n",
       " 'think',\n",
       " 'trick',\n",
       " 'even',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'silly',\n",
       " 'try',\n",
       " 'battery',\n",
       " 'device',\n",
       " 'let',\n",
       " 'charge',\n",
       " 'overnight',\n",
       " 'plug',\n",
       " 'directly',\n",
       " 'wall',\n",
       " 'socket',\n",
       " 'work',\n",
       " 'work',\n",
       " 'well',\n",
       " 'three',\n",
       " 'day',\n",
       " 'later',\n",
       " 'device',\n",
       " 'stop',\n",
       " 'work',\n",
       " 'middle',\n",
       " 'high',\n",
       " 'power',\n",
       " 'usage',\n",
       " 'hair',\n",
       " 'trimmer',\n",
       " 'swap',\n",
       " 'battery',\n",
       " 'two',\n",
       " 'charge',\n",
       " 'entire',\n",
       " 'time',\n",
       " 'work',\n",
       " 'go',\n",
       " 'buy',\n",
       " 'regular',\n",
       " 'aaa',\n",
       " 'battery',\n",
       " 'device',\n",
       " 'go',\n",
       " 'back',\n",
       " 'work',\n",
       " 'fine',\n",
       " 'try',\n",
       " 'battery',\n",
       " 'device',\n",
       " 'work',\n",
       " 'seem',\n",
       " 'work',\n",
       " 'enough',\n",
       " 'convince',\n",
       " 'work',\n",
       " 'stop',\n",
       " 'work',\n",
       " 'often',\n",
       " 'leave',\n",
       " 'feedback',\n",
       " 'product',\n",
       " 'felt',\n",
       " 'important',\n",
       " 'say',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'anyone',\n",
       " 'buy',\n",
       " 'battery',\n",
       " 'totally',\n",
       " 'faulty',\n",
       " 'least',\n",
       " 'completely',\n",
       " 'inconsistent',\n",
       " 'good',\n",
       " 'buying',\n",
       " 'disposable']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to build the optimal LDA model\n",
    "def optimal_lda_model(df, review_colname):\n",
    "    '''\n",
    "    INPUTS:\n",
    "        df_review - dataframe that contains the reviews\n",
    "        review_colname: name of column that contains reviews\n",
    "        \n",
    "    OUTPUTS:\n",
    "        lda_tfidf - Latent Dirichlet Allocation (LDA) model\n",
    "        dtm_tfidf - document-term matrix in the tfidf format\n",
    "        tfidf_vectorizer - word frequency in the reviews\n",
    "        A graph comparing LDA Model Performance Scores with different params\n",
    "    '''\n",
    "    docs_raw = df[review_colname].tolist()\n",
    "\n",
    "    #************   Step 1: Convert to document-term matrix   ************#\n",
    "\n",
    "    #Transform text to vector form using the vectorizer object \n",
    "    tf_vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
    "                                    stop_words = 'english',\n",
    "                                    lowercase = True,\n",
    "                                    token_pattern = r'\\b[a-zA-Z]{3,}\\b', # num chars > 3 to avoid some meaningless words\n",
    "                                    max_df = 0.8,                        # discard words that appear in > 90% of the reviews\n",
    "                                    min_df = 10)                         # discard words that appear in < 10 reviews    \n",
    "\n",
    "    #apply transformation\n",
    "    tfidf_vectorizer = TfidfVectorizer(**tf_vectorizer.get_params())\n",
    "\n",
    "    #convert to document-term matrix\n",
    "    dtm_tfidf = tfidf_vectorizer.fit_transform(docs_raw)  \n",
    "\n",
    "    print(\"The shape of the tfidf is {}, meaning that there are {} {} and {} tokens made through the filtering process.\".\\\n",
    "              format(dtm_tfidf.shape,dtm_tfidf.shape[0], review_colname, dtm_tfidf.shape[1]))\n",
    "\n",
    "    \n",
    "    #*******   Step 2: GridSearch & parameter tuning to find the optimal LDA model   *******#\n",
    "\n",
    "    # Define Search Param\n",
    "    search_params = {'n_components': [5, 10, 15, 20, 25, 30], \n",
    "                     'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "    # Init the Model\n",
    "    lda = LatentDirichletAllocation()\n",
    "\n",
    "    # Init Grid Search Class\n",
    "    model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "    # Do the Grid Search\n",
    "    model.fit(dtm_tfidf)\n",
    "\n",
    "\n",
    "    #*****  Step 3: Output the optimal lda model and its parameters  *****#\n",
    "\n",
    "    # Best Model\n",
    "    best_lda_model = model.best_estimator_\n",
    "\n",
    "    # Model Parameters\n",
    "    print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "    # Log Likelihood Score: Higher the better\n",
    "    print(\"Model Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "    # Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "    print(\"Model Perplexity: \", best_lda_model.perplexity(dtm_tfidf))\n",
    "\n",
    "\n",
    "    #***********   Step 4: Compare LDA Model Performance Scores   ***********#\n",
    "\n",
    "    #Get Log Likelyhoods from Grid Search Output\n",
    "    gscore=model.fit(dtm_tfidf).cv_results_\n",
    "    n_topics = [5, 10, 15, 20, 25, 30]\n",
    "\n",
    "    log_likelyhoods_5 = [gscore['mean_test_score'][gscore['params'].index(v)] for v in gscore['params'] if v['learning_decay']==0.5]\n",
    "    log_likelyhoods_7 = [gscore['mean_test_score'][gscore['params'].index(v)] for v in gscore['params'] if v['learning_decay']==0.7]\n",
    "    log_likelyhoods_9 = [gscore['mean_test_score'][gscore['params'].index(v)] for v in gscore['params'] if v['learning_decay']==0.9]\n",
    "\n",
    "    # Show graph\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(n_topics, log_likelyhoods_5, label='0.5')\n",
    "    plt.plot(n_topics, log_likelyhoods_7, label='0.7')\n",
    "    plt.plot(n_topics, log_likelyhoods_9, label='0.9')\n",
    "    plt.title(\"Choosing Optimal LDA Model\")\n",
    "    plt.xlabel(\"Num Topics\")\n",
    "    plt.ylabel(\"Log Likelyhood Scores\")\n",
    "    plt.legend(title='Learning decay', loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return gscore, best_lda_model, dtm_tfidf, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryankirkland/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:1798: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. <class 'numpy.int64'> 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the tfidf is (4745, 1120), meaning that there are 4745 title_desc and 1120 tokens made through the filtering process.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-837b8c26620f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_lda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtm_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimal_lda_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title_desc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-fed7ae4b58a6>\u001b[0m in \u001b[0;36moptimal_lda_model\u001b[0;34m(df, review_colname)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Do the Grid Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtm_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    578\u001b[0m                     \u001b[0;31m# batch update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                     self._em_step(X, total_samples=n_samples,\n\u001b[0;32m--> 580\u001b[0;31m                                   batch_update=True, parallel=parallel)\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0;31m# check perplexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36m_em_step\u001b[0;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# E-step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         _, suff_stats = self._e_step(X, cal_sstats=True, random_init=True,\n\u001b[0;32m--> 448\u001b[0;31m                                      parallel=parallel)\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;31m# M-step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36m_e_step\u001b[0;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[1;32m    399\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_change_tol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal_sstats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                                               random_state)\n\u001b[0;32m--> 401\u001b[0;31m             for idx_slice in gen_even_slices(X.shape[0], n_jobs))\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# merge result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36m_update_doc_distribution\u001b[0;34m(X, exp_topic_word_distr, doc_topic_prior, max_iters, mean_change_tol, cal_sstats, random_state)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# Note: adds doc_topic_prior to doc_topic_d, in-place.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             _dirichlet_expectation_1d(doc_topic_d, doc_topic_prior,\n\u001b[0;32m--> 119\u001b[0;31m                                       exp_doc_topic_d)\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmean_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmean_change_tol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gscore, best_lda_model, dtm_tfidf, tfidf_vectorizer = optimal_lda_model(cleaned, 'title_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pd.DataFrame(gscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_decay</th>\n",
       "      <th>param_n_components</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.845956</td>\n",
       "      <td>0.104144</td>\n",
       "      <td>0.153028</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_decay': 0.5, 'n_components': 5}</td>\n",
       "      <td>-28488.558606</td>\n",
       "      <td>-28930.989002</td>\n",
       "      <td>-27153.294572</td>\n",
       "      <td>-22561.875711</td>\n",
       "      <td>-22773.777617</td>\n",
       "      <td>-25981.699101</td>\n",
       "      <td>2769.160296</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.790072</td>\n",
       "      <td>0.136663</td>\n",
       "      <td>0.127356</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_decay': 0.5, 'n_components': 10}</td>\n",
       "      <td>-33087.416985</td>\n",
       "      <td>-33513.216148</td>\n",
       "      <td>-30551.072069</td>\n",
       "      <td>-25346.915472</td>\n",
       "      <td>-26303.785883</td>\n",
       "      <td>-29760.481311</td>\n",
       "      <td>3382.450596</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.786485</td>\n",
       "      <td>0.221351</td>\n",
       "      <td>0.133783</td>\n",
       "      <td>0.008054</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>{'learning_decay': 0.5, 'n_components': 15}</td>\n",
       "      <td>-35253.444208</td>\n",
       "      <td>-35915.864000</td>\n",
       "      <td>-34697.528019</td>\n",
       "      <td>-28949.165100</td>\n",
       "      <td>-28021.033834</td>\n",
       "      <td>-32567.407032</td>\n",
       "      <td>3368.250559</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.026420</td>\n",
       "      <td>0.134606</td>\n",
       "      <td>0.138743</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_decay': 0.5, 'n_components': 20}</td>\n",
       "      <td>-38738.205443</td>\n",
       "      <td>-39143.454406</td>\n",
       "      <td>-37213.094375</td>\n",
       "      <td>-32353.431606</td>\n",
       "      <td>-30823.541876</td>\n",
       "      <td>-35654.345541</td>\n",
       "      <td>3416.034759</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.966580</td>\n",
       "      <td>0.118991</td>\n",
       "      <td>0.137061</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_decay': 0.5, 'n_components': 25}</td>\n",
       "      <td>-40890.790108</td>\n",
       "      <td>-42208.995511</td>\n",
       "      <td>-38992.560353</td>\n",
       "      <td>-33969.188965</td>\n",
       "      <td>-33496.305939</td>\n",
       "      <td>-37911.568175</td>\n",
       "      <td>3565.082989</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.834590</td>\n",
       "      <td>0.165225</td>\n",
       "      <td>0.136654</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_decay': 0.5, 'n_components': 30}</td>\n",
       "      <td>-42312.718053</td>\n",
       "      <td>-42835.708947</td>\n",
       "      <td>-40528.415772</td>\n",
       "      <td>-35837.246247</td>\n",
       "      <td>-36164.727810</td>\n",
       "      <td>-39535.763366</td>\n",
       "      <td>2987.620678</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.020092</td>\n",
       "      <td>0.193916</td>\n",
       "      <td>0.153264</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_decay': 0.7, 'n_components': 5}</td>\n",
       "      <td>-28384.681008</td>\n",
       "      <td>-28500.782516</td>\n",
       "      <td>-27141.818990</td>\n",
       "      <td>-22248.838749</td>\n",
       "      <td>-22571.661941</td>\n",
       "      <td>-25769.556641</td>\n",
       "      <td>2785.805419</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.220248</td>\n",
       "      <td>0.150028</td>\n",
       "      <td>0.149348</td>\n",
       "      <td>0.017156</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_decay': 0.7, 'n_components': 10}</td>\n",
       "      <td>-32136.400816</td>\n",
       "      <td>-32668.045994</td>\n",
       "      <td>-31263.006276</td>\n",
       "      <td>-25633.120238</td>\n",
       "      <td>-26415.223464</td>\n",
       "      <td>-29623.159358</td>\n",
       "      <td>2982.887194</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.390310</td>\n",
       "      <td>0.393962</td>\n",
       "      <td>0.143945</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>{'learning_decay': 0.7, 'n_components': 15}</td>\n",
       "      <td>-35405.972626</td>\n",
       "      <td>-36358.420192</td>\n",
       "      <td>-33618.448165</td>\n",
       "      <td>-29563.799087</td>\n",
       "      <td>-28930.848376</td>\n",
       "      <td>-32775.497689</td>\n",
       "      <td>3018.729329</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.142307</td>\n",
       "      <td>0.124830</td>\n",
       "      <td>0.137806</td>\n",
       "      <td>0.014752</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_decay': 0.7, 'n_components': 20}</td>\n",
       "      <td>-37413.359244</td>\n",
       "      <td>-38599.003660</td>\n",
       "      <td>-37385.390037</td>\n",
       "      <td>-30739.987513</td>\n",
       "      <td>-31671.982882</td>\n",
       "      <td>-35161.944667</td>\n",
       "      <td>3272.903597</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.848557</td>\n",
       "      <td>0.275192</td>\n",
       "      <td>0.134378</td>\n",
       "      <td>0.007419</td>\n",
       "      <td>0.7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_decay': 0.7, 'n_components': 25}</td>\n",
       "      <td>-41308.243278</td>\n",
       "      <td>-41241.056900</td>\n",
       "      <td>-37776.620317</td>\n",
       "      <td>-33433.514468</td>\n",
       "      <td>-33856.014091</td>\n",
       "      <td>-37523.089811</td>\n",
       "      <td>3417.221520</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.737570</td>\n",
       "      <td>0.152812</td>\n",
       "      <td>0.133738</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_decay': 0.7, 'n_components': 30}</td>\n",
       "      <td>-42912.140151</td>\n",
       "      <td>-43850.598288</td>\n",
       "      <td>-40847.950884</td>\n",
       "      <td>-34917.495141</td>\n",
       "      <td>-35919.661601</td>\n",
       "      <td>-39689.569213</td>\n",
       "      <td>3633.892372</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.814275</td>\n",
       "      <td>0.126414</td>\n",
       "      <td>0.152432</td>\n",
       "      <td>0.012295</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_decay': 0.9, 'n_components': 5}</td>\n",
       "      <td>-28233.800754</td>\n",
       "      <td>-28663.377834</td>\n",
       "      <td>-27096.922909</td>\n",
       "      <td>-22279.122570</td>\n",
       "      <td>-22358.029536</td>\n",
       "      <td>-25726.250721</td>\n",
       "      <td>2829.164949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.283745</td>\n",
       "      <td>0.414544</td>\n",
       "      <td>0.144162</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_decay': 0.9, 'n_components': 10}</td>\n",
       "      <td>-32388.195499</td>\n",
       "      <td>-32939.353683</td>\n",
       "      <td>-31174.632342</td>\n",
       "      <td>-26850.588824</td>\n",
       "      <td>-26296.863886</td>\n",
       "      <td>-29929.926847</td>\n",
       "      <td>2804.656683</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.894476</td>\n",
       "      <td>0.155976</td>\n",
       "      <td>0.136125</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.9</td>\n",
       "      <td>15</td>\n",
       "      <td>{'learning_decay': 0.9, 'n_components': 15}</td>\n",
       "      <td>-34367.585513</td>\n",
       "      <td>-37050.195673</td>\n",
       "      <td>-33863.430047</td>\n",
       "      <td>-29098.199969</td>\n",
       "      <td>-28309.757282</td>\n",
       "      <td>-32537.833697</td>\n",
       "      <td>3321.876528</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.836675</td>\n",
       "      <td>0.124257</td>\n",
       "      <td>0.132903</td>\n",
       "      <td>0.010458</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_decay': 0.9, 'n_components': 20}</td>\n",
       "      <td>-38753.627273</td>\n",
       "      <td>-39044.787415</td>\n",
       "      <td>-36366.257228</td>\n",
       "      <td>-32174.173800</td>\n",
       "      <td>-31393.346284</td>\n",
       "      <td>-35546.438400</td>\n",
       "      <td>3219.222014</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.834491</td>\n",
       "      <td>0.164795</td>\n",
       "      <td>0.133474</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.9</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_decay': 0.9, 'n_components': 25}</td>\n",
       "      <td>-40646.687393</td>\n",
       "      <td>-40750.529572</td>\n",
       "      <td>-39331.553379</td>\n",
       "      <td>-32836.979462</td>\n",
       "      <td>-32857.842642</td>\n",
       "      <td>-37284.718490</td>\n",
       "      <td>3657.426053</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.947068</td>\n",
       "      <td>0.133797</td>\n",
       "      <td>0.142573</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>0.9</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_decay': 0.9, 'n_components': 30}</td>\n",
       "      <td>-42668.175619</td>\n",
       "      <td>-44303.074287</td>\n",
       "      <td>-41380.703829</td>\n",
       "      <td>-34907.278409</td>\n",
       "      <td>-35309.299519</td>\n",
       "      <td>-39713.706333</td>\n",
       "      <td>3874.806225</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        5.845956      0.104144         0.153028        0.008257   \n",
       "1        4.790072      0.136663         0.127356        0.009912   \n",
       "2        4.786485      0.221351         0.133783        0.008054   \n",
       "3        5.026420      0.134606         0.138743        0.009025   \n",
       "4        4.966580      0.118991         0.137061        0.011771   \n",
       "5        4.834590      0.165225         0.136654        0.008059   \n",
       "6        6.020092      0.193916         0.153264        0.005375   \n",
       "7        5.220248      0.150028         0.149348        0.017156   \n",
       "8        5.390310      0.393962         0.143945        0.005179   \n",
       "9        5.142307      0.124830         0.137806        0.014752   \n",
       "10       4.848557      0.275192         0.134378        0.007419   \n",
       "11       4.737570      0.152812         0.133738        0.009334   \n",
       "12       5.814275      0.126414         0.152432        0.012295   \n",
       "13       5.283745      0.414544         0.144162        0.012471   \n",
       "14       4.894476      0.155976         0.136125        0.009681   \n",
       "15       4.836675      0.124257         0.132903        0.010458   \n",
       "16       4.834491      0.164795         0.133474        0.008701   \n",
       "17       4.947068      0.133797         0.142573        0.008778   \n",
       "\n",
       "   param_learning_decay param_n_components  \\\n",
       "0                   0.5                  5   \n",
       "1                   0.5                 10   \n",
       "2                   0.5                 15   \n",
       "3                   0.5                 20   \n",
       "4                   0.5                 25   \n",
       "5                   0.5                 30   \n",
       "6                   0.7                  5   \n",
       "7                   0.7                 10   \n",
       "8                   0.7                 15   \n",
       "9                   0.7                 20   \n",
       "10                  0.7                 25   \n",
       "11                  0.7                 30   \n",
       "12                  0.9                  5   \n",
       "13                  0.9                 10   \n",
       "14                  0.9                 15   \n",
       "15                  0.9                 20   \n",
       "16                  0.9                 25   \n",
       "17                  0.9                 30   \n",
       "\n",
       "                                         params  split0_test_score  \\\n",
       "0    {'learning_decay': 0.5, 'n_components': 5}      -28488.558606   \n",
       "1   {'learning_decay': 0.5, 'n_components': 10}      -33087.416985   \n",
       "2   {'learning_decay': 0.5, 'n_components': 15}      -35253.444208   \n",
       "3   {'learning_decay': 0.5, 'n_components': 20}      -38738.205443   \n",
       "4   {'learning_decay': 0.5, 'n_components': 25}      -40890.790108   \n",
       "5   {'learning_decay': 0.5, 'n_components': 30}      -42312.718053   \n",
       "6    {'learning_decay': 0.7, 'n_components': 5}      -28384.681008   \n",
       "7   {'learning_decay': 0.7, 'n_components': 10}      -32136.400816   \n",
       "8   {'learning_decay': 0.7, 'n_components': 15}      -35405.972626   \n",
       "9   {'learning_decay': 0.7, 'n_components': 20}      -37413.359244   \n",
       "10  {'learning_decay': 0.7, 'n_components': 25}      -41308.243278   \n",
       "11  {'learning_decay': 0.7, 'n_components': 30}      -42912.140151   \n",
       "12   {'learning_decay': 0.9, 'n_components': 5}      -28233.800754   \n",
       "13  {'learning_decay': 0.9, 'n_components': 10}      -32388.195499   \n",
       "14  {'learning_decay': 0.9, 'n_components': 15}      -34367.585513   \n",
       "15  {'learning_decay': 0.9, 'n_components': 20}      -38753.627273   \n",
       "16  {'learning_decay': 0.9, 'n_components': 25}      -40646.687393   \n",
       "17  {'learning_decay': 0.9, 'n_components': 30}      -42668.175619   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0       -28930.989002      -27153.294572      -22561.875711   \n",
       "1       -33513.216148      -30551.072069      -25346.915472   \n",
       "2       -35915.864000      -34697.528019      -28949.165100   \n",
       "3       -39143.454406      -37213.094375      -32353.431606   \n",
       "4       -42208.995511      -38992.560353      -33969.188965   \n",
       "5       -42835.708947      -40528.415772      -35837.246247   \n",
       "6       -28500.782516      -27141.818990      -22248.838749   \n",
       "7       -32668.045994      -31263.006276      -25633.120238   \n",
       "8       -36358.420192      -33618.448165      -29563.799087   \n",
       "9       -38599.003660      -37385.390037      -30739.987513   \n",
       "10      -41241.056900      -37776.620317      -33433.514468   \n",
       "11      -43850.598288      -40847.950884      -34917.495141   \n",
       "12      -28663.377834      -27096.922909      -22279.122570   \n",
       "13      -32939.353683      -31174.632342      -26850.588824   \n",
       "14      -37050.195673      -33863.430047      -29098.199969   \n",
       "15      -39044.787415      -36366.257228      -32174.173800   \n",
       "16      -40750.529572      -39331.553379      -32836.979462   \n",
       "17      -44303.074287      -41380.703829      -34907.278409   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0       -22773.777617    -25981.699101     2769.160296                3  \n",
       "1       -26303.785883    -29760.481311     3382.450596                5  \n",
       "2       -28021.033834    -32567.407032     3368.250559                8  \n",
       "3       -30823.541876    -35654.345541     3416.034759               12  \n",
       "4       -33496.305939    -37911.568175     3565.082989               15  \n",
       "5       -36164.727810    -39535.763366     2987.620678               16  \n",
       "6       -22571.661941    -25769.556641     2785.805419                2  \n",
       "7       -26415.223464    -29623.159358     2982.887194                4  \n",
       "8       -28930.848376    -32775.497689     3018.729329                9  \n",
       "9       -31671.982882    -35161.944667     3272.903597               10  \n",
       "10      -33856.014091    -37523.089811     3417.221520               14  \n",
       "11      -35919.661601    -39689.569213     3633.892372               17  \n",
       "12      -22358.029536    -25726.250721     2829.164949                1  \n",
       "13      -26296.863886    -29929.926847     2804.656683                6  \n",
       "14      -28309.757282    -32537.833697     3321.876528                7  \n",
       "15      -31393.346284    -35546.438400     3219.222014               11  \n",
       "16      -32857.842642    -37284.718490     3657.426053               13  \n",
       "17      -35309.299519    -39713.706333     3874.806225               18  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1 words</th>\n",
       "      <th>Topic 1 weights</th>\n",
       "      <th>Topic 2 words</th>\n",
       "      <th>Topic 2 weights</th>\n",
       "      <th>Topic 3 words</th>\n",
       "      <th>Topic 3 weights</th>\n",
       "      <th>Topic 4 words</th>\n",
       "      <th>Topic 4 weights</th>\n",
       "      <th>Topic 5 words</th>\n",
       "      <th>Topic 5 weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batteries</td>\n",
       "      <td>74.2</td>\n",
       "      <td>batteries</td>\n",
       "      <td>100.2</td>\n",
       "      <td>batteries</td>\n",
       "      <td>127.3</td>\n",
       "      <td>great</td>\n",
       "      <td>194.1</td>\n",
       "      <td>batteries</td>\n",
       "      <td>43.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>charge</td>\n",
       "      <td>40.9</td>\n",
       "      <td>charge</td>\n",
       "      <td>80.4</td>\n",
       "      <td>usb</td>\n",
       "      <td>80.4</td>\n",
       "      <td>good</td>\n",
       "      <td>146.9</td>\n",
       "      <td>lights</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work</td>\n",
       "      <td>38.1</td>\n",
       "      <td>battery</td>\n",
       "      <td>50.9</td>\n",
       "      <td>good</td>\n",
       "      <td>72.8</td>\n",
       "      <td>works</td>\n",
       "      <td>101.5</td>\n",
       "      <td>good</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>money</td>\n",
       "      <td>35.1</td>\n",
       "      <td>use</td>\n",
       "      <td>41.9</td>\n",
       "      <td>rechargeable</td>\n",
       "      <td>67.6</td>\n",
       "      <td>product</td>\n",
       "      <td>89.2</td>\n",
       "      <td>worked</td>\n",
       "      <td>24.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buy</td>\n",
       "      <td>34.6</td>\n",
       "      <td>charged</td>\n",
       "      <td>40.4</td>\n",
       "      <td>battery</td>\n",
       "      <td>66.5</td>\n",
       "      <td>value</td>\n",
       "      <td>70.7</td>\n",
       "      <td>work</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>use</td>\n",
       "      <td>30.6</td>\n",
       "      <td>hold</td>\n",
       "      <td>40.2</td>\n",
       "      <td>charge</td>\n",
       "      <td>65.9</td>\n",
       "      <td>batteries</td>\n",
       "      <td>70.3</td>\n",
       "      <td>fine</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>long</td>\n",
       "      <td>26.1</td>\n",
       "      <td>long</td>\n",
       "      <td>38.7</td>\n",
       "      <td>charger</td>\n",
       "      <td>55.6</td>\n",
       "      <td>price</td>\n",
       "      <td>66.3</td>\n",
       "      <td>charger</td>\n",
       "      <td>23.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>don</td>\n",
       "      <td>25.7</td>\n",
       "      <td>camera</td>\n",
       "      <td>38.4</td>\n",
       "      <td>charging</td>\n",
       "      <td>52.3</td>\n",
       "      <td>long</td>\n",
       "      <td>53.9</td>\n",
       "      <td>battery</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>china</td>\n",
       "      <td>25.6</td>\n",
       "      <td>hours</td>\n",
       "      <td>34.2</td>\n",
       "      <td>like</td>\n",
       "      <td>49.1</td>\n",
       "      <td>work</td>\n",
       "      <td>49.4</td>\n",
       "      <td>charged</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>japan</td>\n",
       "      <td>22.6</td>\n",
       "      <td>don</td>\n",
       "      <td>31.0</td>\n",
       "      <td>great</td>\n",
       "      <td>48.6</td>\n",
       "      <td>far</td>\n",
       "      <td>43.6</td>\n",
       "      <td>charge</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>good</td>\n",
       "      <td>22.5</td>\n",
       "      <td>work</td>\n",
       "      <td>30.9</td>\n",
       "      <td>use</td>\n",
       "      <td>42.6</td>\n",
       "      <td>excellent</td>\n",
       "      <td>42.6</td>\n",
       "      <td>light</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>great</td>\n",
       "      <td>22.1</td>\n",
       "      <td>using</td>\n",
       "      <td>30.8</td>\n",
       "      <td>time</td>\n",
       "      <td>36.8</td>\n",
       "      <td>love</td>\n",
       "      <td>35.1</td>\n",
       "      <td>fit</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>recharge</td>\n",
       "      <td>22.1</td>\n",
       "      <td>months</td>\n",
       "      <td>29.3</td>\n",
       "      <td>nice</td>\n",
       "      <td>35.1</td>\n",
       "      <td>use</td>\n",
       "      <td>34.4</td>\n",
       "      <td>solar</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>battery</td>\n",
       "      <td>21.4</td>\n",
       "      <td>time</td>\n",
       "      <td>28.7</td>\n",
       "      <td>long</td>\n",
       "      <td>34.6</td>\n",
       "      <td>charge</td>\n",
       "      <td>34.2</td>\n",
       "      <td>thanks</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>remote</td>\n",
       "      <td>21.3</td>\n",
       "      <td>good</td>\n",
       "      <td>26.5</td>\n",
       "      <td>aaa</td>\n",
       "      <td>30.4</td>\n",
       "      <td>easy</td>\n",
       "      <td>33.5</td>\n",
       "      <td>charging</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bought</td>\n",
       "      <td>21.2</td>\n",
       "      <td>rechargeable</td>\n",
       "      <td>26.3</td>\n",
       "      <td>port</td>\n",
       "      <td>28.8</td>\n",
       "      <td>expected</td>\n",
       "      <td>32.5</td>\n",
       "      <td>used</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>amazon</td>\n",
       "      <td>21.0</td>\n",
       "      <td>dead</td>\n",
       "      <td>26.0</td>\n",
       "      <td>cable</td>\n",
       "      <td>27.2</td>\n",
       "      <td>perfect</td>\n",
       "      <td>29.9</td>\n",
       "      <td>does</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time</td>\n",
       "      <td>20.4</td>\n",
       "      <td>life</td>\n",
       "      <td>25.3</td>\n",
       "      <td>plug</td>\n",
       "      <td>26.8</td>\n",
       "      <td>fast</td>\n",
       "      <td>29.9</td>\n",
       "      <td>just</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hold</td>\n",
       "      <td>19.7</td>\n",
       "      <td>just</td>\n",
       "      <td>25.2</td>\n",
       "      <td>best</td>\n",
       "      <td>25.9</td>\n",
       "      <td>money</td>\n",
       "      <td>29.0</td>\n",
       "      <td>led</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>used</td>\n",
       "      <td>19.7</td>\n",
       "      <td>power</td>\n",
       "      <td>23.6</td>\n",
       "      <td>easy</td>\n",
       "      <td>25.5</td>\n",
       "      <td>battery</td>\n",
       "      <td>29.0</td>\n",
       "      <td>great</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic 1 words Topic 1 weights Topic 2 words Topic 2 weights Topic 3 words  \\\n",
       "0      batteries            74.2     batteries           100.2     batteries   \n",
       "1         charge            40.9        charge            80.4           usb   \n",
       "2           work            38.1       battery            50.9          good   \n",
       "3          money            35.1           use            41.9  rechargeable   \n",
       "4            buy            34.6       charged            40.4       battery   \n",
       "5            use            30.6          hold            40.2        charge   \n",
       "6           long            26.1          long            38.7       charger   \n",
       "7            don            25.7        camera            38.4      charging   \n",
       "8          china            25.6         hours            34.2          like   \n",
       "9          japan            22.6           don            31.0         great   \n",
       "10          good            22.5          work            30.9           use   \n",
       "11         great            22.1         using            30.8          time   \n",
       "12      recharge            22.1        months            29.3          nice   \n",
       "13       battery            21.4          time            28.7          long   \n",
       "14        remote            21.3          good            26.5           aaa   \n",
       "15        bought            21.2  rechargeable            26.3          port   \n",
       "16        amazon            21.0          dead            26.0         cable   \n",
       "17          time            20.4          life            25.3          plug   \n",
       "18          hold            19.7          just            25.2          best   \n",
       "19          used            19.7         power            23.6          easy   \n",
       "\n",
       "   Topic 3 weights Topic 4 words Topic 4 weights Topic 5 words Topic 5 weights  \n",
       "0            127.3         great           194.1     batteries            43.3  \n",
       "1             80.4          good           146.9        lights            26.0  \n",
       "2             72.8         works           101.5          good            24.9  \n",
       "3             67.6       product            89.2        worked            24.6  \n",
       "4             66.5         value            70.7          work            23.8  \n",
       "5             65.9     batteries            70.3          fine            23.6  \n",
       "6             55.6         price            66.3       charger            23.4  \n",
       "7             52.3          long            53.9       battery            20.9  \n",
       "8             49.1          work            49.4       charged            20.0  \n",
       "9             48.6           far            43.6        charge            19.2  \n",
       "10            42.6     excellent            42.6         light            18.6  \n",
       "11            36.8          love            35.1           fit            18.6  \n",
       "12            35.1           use            34.4         solar            18.5  \n",
       "13            34.6        charge            34.2        thanks            17.7  \n",
       "14            30.4          easy            33.5      charging            17.4  \n",
       "15            28.8      expected            32.5          used            17.1  \n",
       "16            27.2       perfect            29.9          does            16.9  \n",
       "17            26.8          fast            29.9          just            16.8  \n",
       "18            25.9         money            29.0           led            13.6  \n",
       "19            25.5       battery            29.0         great            13.5  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a function to inspect the topics we created \n",
    "def display_topics(model, feature_names, n_top_words):\n",
    "    '''\n",
    "    INPUTS:\n",
    "        model - the model we created\n",
    "        feature_names - tells us what word each column in the matric represents\n",
    "        n_top_words - number of top words to display\n",
    "\n",
    "    OUTPUTS:\n",
    "        a dataframe that contains the topics we created and the weights of each token\n",
    "    '''\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx+1)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx+1)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)\n",
    "\n",
    "\n",
    "display_topics(best_lda_model, tfidf_vectorizer.get_feature_names(), n_top_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cleaned['processed_reviews'] = cleaned['title_desc'].apply(lambda x: re.sub('[,\\.!?]', '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned['processed_reviews'] = cleaned['processed_reviews'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_to_words(reviews):\n",
    "    review_list = reviews.values.tolist()\n",
    "    for review in reviews:\n",
    "        yield(simple_preprocess(review, deacc=True)) #deacc=True removes punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(reviews_to_words(cleaned['processed_reviews']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = gensim.models.Phrases(tokens, min_count=2)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ryankirkland/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Define functions for stopwords, lemmatization, bigrams, and trigrams\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return[[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryankirkland/anaconda3/lib/python3.7/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(tokens)\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 7), (2, 1), (3, 1), (4, 1), (5, 1), (6, 3), (7, 1), (8, 4), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 5), (15, 2), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 2), (54, 2), (55, 1), (56, 1), (57, 1), (58, 3), (59, 1), (60, 3), (61, 2), (62, 1), (63, 9), (64, 1), (65, 1), (66, 1)]]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=5, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.095*\"battery\" + 0.041*\"charge\" + 0.024*\"charger\" + 0.020*\"use\" + '\n",
      "  '0.016*\"rechargeable\" + 0.013*\"usb\" + 0.012*\"great\" + 0.009*\"need\" + '\n",
      "  '0.008*\"come\" + 0.008*\"device\"'),\n",
      " (1,\n",
      "  '0.084*\"good\" + 0.057*\"battery\" + 0.023*\"price\" + 0.021*\"far\" + 0.021*\"use\" '\n",
      "  '+ 0.017*\"product\" + 0.017*\"great\" + 0.016*\"make\" + 0.015*\"seem\" + '\n",
      "  '0.013*\"charge\"'),\n",
      " (2,\n",
      "  '0.056*\"use\" + 0.050*\"battery\" + 0.039*\"great\" + 0.036*\"work\" + '\n",
      "  '0.025*\"charge\" + 0.020*\"good\" + 0.015*\"recharge\" + 0.013*\"remote\" + '\n",
      "  '0.011*\"love\" + 0.011*\"expect\"'),\n",
      " (3,\n",
      "  '0.074*\"battery\" + 0.025*\"rechargeable\" + 0.023*\"last\" + 0.022*\"use\" + '\n",
      "  '0.021*\"buy\" + 0.017*\"charge\" + 0.016*\"work\" + 0.015*\"great\" + 0.013*\"money\" '\n",
      "  '+ 0.012*\"year\"'),\n",
      " (4,\n",
      "  '0.077*\"battery\" + 0.048*\"charge\" + 0.026*\"use\" + 0.015*\"time\" + 0.014*\"buy\" '\n",
      "  '+ 0.012*\"work\" + 0.012*\"get\" + 0.010*\"go\" + 0.010*\"light\" + 0.010*\"last\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.45817196130119875\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
